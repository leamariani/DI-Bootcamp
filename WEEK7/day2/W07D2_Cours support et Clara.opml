<?xml version="1.0" encoding="UTF-8"?>
<opml version="1.0" xmlns:sx="http://www.microsoft.com/schemas/rss/sse"><head><title>W07D2_Cours du support et de Clara_ Réglage fin efficace des paramètres et LoRA pour LLM et ViT</title><dateCreated>2025-07-21T16:54:36</dateCreated><dateModified>2025-07-22T11:06:02</dateModified><ownerName>abacus</ownerName></head><body><outline text="Introduction générale"><outline text="Réglage fin efficace (PEFT) et transfert learning"><sx:sync version="1" id="Kh8rCgofl0yQhyfhwgosYg==" /></outline><outline text="Objectif : Adapter LLM et ViT à des tâches spécifiques à moindre coût"><sx:sync version="1" id="aLpjrKjQBUCjtAQQg6BNlg==" /></outline><outline text="Problème : Grands modèles = &quot;trop puissants&quot; pour des cas spécialisés"><sx:sync version="1" id="p2pfELQuGkmQn8YuuMdFUg==" /></outline><outline text="Solution : Transformer un modèle généraliste en modèle spécialisé"><sx:sync version="1" id="pwniefMl70qhEx85xisb/A==" /></outline><sx:sync version="1" id="mbAhqT+uh02CWLdeHK0AXg==" /></outline><outline text="Les modèles de fondation"><outline text="1. Définition"><outline text="- Modèles pré-entraînés sur d'énormes quantités de données généralistes."><sx:sync version="1" id="nLHZkilbGkGo+SeA6arEhQ==" /></outline><outline text="- Servent de base polyvalente pour plusieurs tâches (texte, image, audio…)."><sx:sync version="1" id="OkHwjH3I2EWp7CqlAPtvAQ==" /></outline><sx:sync version="1" id="p5nOYN9zskGSGJuAt0swyw==" /></outline><outline text="2. Caractéristiques"><outline text="- Très grande taille (millions ou milliards de paramètres)."><sx:sync version="1" id="iKhdWHibikCJLYxbDhHHHQ==" /></outline><outline text="- Pré-entraînement auto-supervisé sur données massives."><sx:sync version="1" id="lcMJ5xTYAEG5MOZXWNzkTQ==" /></outline><outline text="- Réutilisables pour différents usages via fine-tuning, LoRA, RAG."><sx:sync version="1" id="SKAP1AunxESQ98gDWlYA4w==" /></outline><sx:sync version="1" id="IbBzQLi/QkC33UVNmtMTog==" /></outline><outline text="3. Exemples"><outline text="- Modèles de langage : GPT, Llama, Mistral, Claude."><sx:sync version="1" id="j90G+Ja3u02aJolOe1HHMg==" /></outline><outline text="- Modèles de vision : CLIP, SAM (Segment Anything Model)."><sx:sync version="1" id="xJ3wM8Z+Y0at9tTl9UkxHQ==" /></outline><outline text="- Modèles multimodaux : GPT-4o, Kosmos, Flamingo."><sx:sync version="1" id="QQ4z4plOBUivZuK85MD+2w==" /></outline><outline text="- Modèles audio : Whisper, EnCodec."><sx:sync version="1" id="f8gbPKXoDkeLk5WyVO/dwQ==" /></outline><outline text="- Modèles de code : Codex, CodeLlama, Starcoder."><sx:sync version="1" id="v4fijENnD0G53kVIY5rWiQ==" /></outline><sx:sync version="1" id="Z232ivgWVUq1OQr7Rjtrkw==" /></outline><outline text="4. Avantages"><outline text="- Réduction des coûts de développement pour des applications spécialisées."><sx:sync version="1" id="r7Tdztag0EuqmC8cdZqQPw==" /></outline><outline text="- Polyvalence : un modèle peut faire plusieurs tâches."><sx:sync version="1" id="m3fejphu+0SpFStr2UjkFA==" /></outline><outline text="- Adaptable avec peu de données supplémentaires."><sx:sync version="1" id="hvXD0kOGLUuMO6S7AHjjGw==" /></outline><sx:sync version="1" id="wfQQyQb4i0G85q7/+PGkfQ==" /></outline><outline text="5. Inconvénients"><outline text="- Modèles lourds, coûteux à manipuler sans adaptation."><sx:sync version="1" id="zQUsFmnZmUuCkiCodA9wNg==" /></outline><outline text="- Risque de biais dus aux données généralistes."><sx:sync version="1" id="SNIVN+Cbk02fEBG2O7YZ4w==" /></outline><outline text="- Nécessité d’adaptations pour des cas d’usage précis."><sx:sync version="1" id="I6Uj3TRkNUS/MrnHKXuJxA==" /></outline><sx:sync version="1" id="Y5MOZpNZHU6k//pLIK4/tA==" /></outline><sx:sync version="1" id="SxpwUME1wEytheIBJHL3Tg==" /></outline><outline text="Défis du réglage fin complet"><outline text="2.1. Trop de paramètres"><outline text="Coût mémoire, calcul, temps élevés"><sx:sync version="1" id="u71MswRDjUi4hfkiyDTnug==" /></outline><sx:sync version="1" id="wfB7YyLBKkK18ExDnvy71Q==" /></outline><outline text="2.2. Surcharge de stockage"><outline text="Chaque version fine-tunée = copie complète du modèle"><sx:sync version="1" id="LzFef5PkhEKl9up4qDnEZA==" /></outline><sx:sync version="1" id="BuURyLoFhEWNIzy3z61BpQ==" /></outline><outline text="2.3. Coût computationnel élevé"><outline text="GPU/TPU requis, processus coûteux"><sx:sync version="1" id="i7J1s/pYEEuWKmC8s3gU2w==" /></outline><sx:sync version="1" id="npXVJL7D/0mb3uT0YBHhrQ==" /></outline><outline text="2.4. Surapprentissage et oubli catastrophique"><outline text="Risque d’écraser les connaissances générales du modèle"><sx:sync version="1" id="sczyJx6wtkWDGZZaTMvM4g==" /></outline><sx:sync version="1" id="0FytkggDFkS/HE4cZbMniQ==" /></outline><sx:sync version="1" id="011U4KW2Zkm52qj7fdBYWw==" /></outline><outline text="Le Finetuning"><outline text="1. Full Fine-Tuning"><outline text="- Réentraînement complet de tous les paramètres du modèle."><sx:sync version="1" id="uOiyBvdwlk+FsMMeQN/kaQ==" /></outline><outline text="- Nécessite beaucoup de ressources mais permet une adaptation maximale."><sx:sync version="1" id="SMNh/s8L60iTaBQ3/YUTEw==" /></outline><sx:sync version="1" id="AvguRrU4u0+Rzugn75Y3LA==" /></outline><outline text="2. Fine-Tuning Partiel"><outline text="- Seules certaines couches sont entraînées (ex : les dernières couches)."><sx:sync version="1" id="VipHSOn6YUSggR+WH2C8sg==" /></outline><outline text="- Moins coûteux, utile pour des ajustements rapides."><sx:sync version="1" id="1Pa3i7vaFEm3el2zq1m6Cw==" /></outline><sx:sync version="1" id="DZNqi/roRkmtkLh2zFg9wA==" /></outline><outline text="3. LoRA (Low-Rank Adaptation)"><outline text="- Ajout de petites matrices entraînables sur certaines couches."><sx:sync version="1" id="8mDNYWSHKUC5SW9TMm6PsA==" /></outline><outline text="- Très léger, rapide, sans modifier les poids principaux."><sx:sync version="1" id="K73dkREh90CdXJ+vFxpBfA==" /></outline><sx:sync version="1" id="8Y9qC1gGH0y0kSd2UbHWMw==" /></outline><outline text="4. QLoRA"><outline text="- LoRA combiné à une quantisation 4 bits pour réduire encore plus la mémoire utilisée."><sx:sync version="1" id="37LsZld0E0SmzThaeEaY7A==" /></outline><outline text="- Permet un fine-tuning efficace sur GPU moyen (16-24GB)."><sx:sync version="1" id="tvnRCxuBI0GkiGVcqAMxnA==" /></outline><sx:sync version="1" id="o+Bhfhrho0iWhSPZFukr1Q==" /></outline><outline text="5. PEFT (Parameter-Efficient Fine-Tuning)"><outline text="- Terme général regroupant LoRA, Prefix-Tuning, Adapter-Tuning, etc."><sx:sync version="1" id="NBn4oplUD0quyQ7KlU1M7w==" /></outline><outline text="- Objectif : réduire drastiquement le nombre de paramètres entraînés."><sx:sync version="1" id="2/8zodqO0kObwXNDUzAUjw==" /></outline><sx:sync version="1" id="K97SUIdWAEK0fB4iDUhFYQ==" /></outline><outline text="6. Prefix-Tuning"><outline text="- Ajout de préfixes entraînables au début des séquences d’entrée."><sx:sync version="1" id="b7E230D0r0Gd6vJlD9IQJQ==" /></outline><outline text="- Très léger, peu intrusif, sans modification interne du modèle."><sx:sync version="1" id="P4x3o/pun0OJcZdhzQB9Gg==" /></outline><sx:sync version="1" id="c0nEJxDqh0qRRdZUh1762A==" /></outline><outline text="7. Adapter-Tuning"><outline text="- Insertion de petites couches supplémentaires entre les couches du modèle, uniquement celles-ci sont entraînées."><sx:sync version="1" id="63R+lV+BakC9q+ApAldP8A==" /></outline><outline text="- Peu gourmand en ressources, facilement amovible."><sx:sync version="1" id="4gLhp6WI6EO3YoGT1dMq3Q==" /></outline><sx:sync version="1" id="CGUNh6NxcUqLevfJ7jIfQw==" /></outline><outline text="8. Prompt-Tuning (ou Soft Prompt)"><outline text="- Fine-tuning de vecteurs prompts (non textuels) pour guider le modèle."><sx:sync version="1" id="lnEbK9LuU0CaAhvBJPmS/g==" /></outline><outline text="- Très économique mais limité à certaines tâches spécifiques."><sx:sync version="1" id="k+Cjqsrpw06GSWcccTULhg==" /></outline><sx:sync version="1" id="DRZKBebZwEqnHRjHQ3vdVQ==" /></outline><outline text="9. Dreambooth (pour la génération d’images)"><outline text="- Fine-tuning sur des images spécifiques pour personnaliser un modèle génératif."><sx:sync version="1" id="nxWa6Nsbs02V0I3DOUqQfw==" /></outline><outline text="- Utilisé pour des cas visuels très personnalisés."><sx:sync version="1" id="woBp5dHLtkyhDajJAQbAfA==" /></outline><sx:sync version="1" id="vI6d2CY+WE+nxegyXMg1aw==" /></outline><outline text="10. Instruction Tuning"><outline text="- Fine-tuning basé sur des paires instruction/réponse pour rendre un modèle plus interactif."><sx:sync version="1" id="kzoAvyywmEa0JEINDWBsPA==" /></outline><outline text="- Fréquent sur les chatbots."><sx:sync version="1" id="9xXgqG7p8Eav0mI3gjNyyQ==" /></outline><sx:sync version="1" id="XAKBMAnvTEuEj5cVGx30Mg==" /></outline><sx:sync version="1" id="ucBu3+hGDkePDKF86k4HBA==" /></outline><outline text="Workflow du Finetuning"><outline text="1. Définir l’objectif"><outline text="- Préciser la tâche : classification, génération de texte, résumé, chatbot, etc."><sx:sync version="1" id="YGZwDYdwH0aliluTPI6/8w==" /></outline><sx:sync version="1" id="iQDbLvGpaUWLR1DinAuerg==" /></outline><outline text="2. Choisir le modèle pré-entraîné"><outline text="- Sélectionner un modèle de base adapté à la tâche (GPT, BERT, Llama…)."><sx:sync version="1" id="KuDJ9K/KB0W1gBb0V7okMQ==" /></outline><sx:sync version="1" id="WqVEK3ca50OQ0/u6SQg2kA==" /></outline><outline text="3. Préparer les données"><outline text="- Collecter des données spécifiques à la tâche."><sx:sync version="1" id="RoB4Vo4b6ES/saATL/puPw==" /></outline><outline text="- Nettoyer, formater (JSON, CSV, instruction-tuning…)."><sx:sync version="1" id="z41ehQTiMUGA4Ni7c3ybzw==" /></outline><outline text="- Séparer en jeu d’entraînement et validation."><sx:sync version="1" id="5V1xZYuagUOBxcz7FNSePA==" /></outline><sx:sync version="1" id="gaKxVGWt00mvntGMw5eCFA==" /></outline><outline text="4. Choisir la méthode de fine-tuning"><outline text="- Full fine-tuning (tout le modèle est entraîné),"><sx:sync version="1" id="N2Pn30RlFUKfXwHqb5T97w==" /></outline><outline text="- Fine-tuning partiel (LoRA, QLoRA, PEFT)."><sx:sync version="1" id="yWeh2MB5iUGVQRrkCBUqFg==" /></outline><sx:sync version="1" id="UMc/YvOfqU+QkpBbXp3PhA==" /></outline><outline text="5. Configurer l’entraînement"><outline text="- Définir les hyperparamètres : epochs, learning rate, batch size."><sx:sync version="1" id="Dw1IWETm002WuUGmtRy/JA==" /></outline><outline text="- Utiliser les bons outils (Hugging Face, PEFT, bitsandbytes)."><sx:sync version="1" id="dUYtsK7XIUCSylHg8I6ccA==" /></outline><sx:sync version="1" id="8DcI81zi806q9T0ywsdLiQ==" /></outline><outline text="6. Lancer l’entraînement"><outline text="- Suivre la progression sur GPU."><sx:sync version="1" id="mPhJidCG3E6xbzWX8agU0Q==" /></outline><outline text="- Évaluer la perte et les performances sur validation."><sx:sync version="1" id="Eqh2Lsstp0qsQjBmBhoDtw==" /></outline><sx:sync version="1" id="cfACYuPCmEu+3As6M8f9AA==" /></outline><outline text="7. Évaluer le modèle fine-tuné"><outline text="- Vérifier les performances sur un jeu de test."><sx:sync version="1" id="u53U0QQ3ikiOxDTQoAHVBg==" /></outline><outline text="- Comparer avec un modèle de base."><sx:sync version="1" id="LzkTOG0ZmkqKEqXl2q+piw==" /></outline><sx:sync version="1" id="Lt2cXUUgwEGwWHpO8QWRCA==" /></outline><outline text="8. Sauvegarder et déployer"><outline text="- Sauvegarder le modèle final."><sx:sync version="1" id="YSq7YzGx10qDuWIk2ANxlA==" /></outline><outline text="- Intégrer dans l’application ou API selon besoin."><sx:sync version="1" id="DKSfA4PJR06KQkrPwkVd3g==" /></outline><sx:sync version="1" id="ZPy3OekDxE6L+5COGi0KBA==" /></outline><outline text="9. (optionnel) Affinage continu"><outline text="- Possibilité de refaire du fine-tuning avec de nouvelles données."><sx:sync version="1" id="muFGPKaFc02T1sX6hDDdwg==" /></outline><sx:sync version="1" id="KNhcdV8PAEiy2N0uud5SNA==" /></outline><sx:sync version="1" id="FYiY5EEfqU2xH5OymELnNQ==" /></outline><outline text="Fine Tuning vs Distillation"><outline text="Fine-Tuning"><outline text="Définition"><outline text="spécialiser un modèle pré-entraîné sur une tâche précise."><sx:sync version="1" id="sgkmHIbZe0Ozt5DO+SlzHg==" /></outline><sx:sync version="1" id="ig6JgKIQzUOiLcPRDX7Tug==" /></outline><outline text="Objectif"><outline text="améliorer la performance sur un domaine spécifique."><sx:sync version="1" id="FMnhHSm3rUiWHUfKexiGww==" /></outline><sx:sync version="1" id="eG2U5VYBw0K1oNpDgJkI5g==" /></outline><outline text="Méthode"><outline text="Soit on réentraîne tout le modèle,"><sx:sync version="1" id="wowbl83Ln0mwFuefbLFkwQ==" /></outline><outline text="Soit on entraîne uniquement certaines parties (ex"><outline text="LoRA)."><sx:sync version="1" id="cw5lKEPQmU+FJRbxgcAoTQ==" /></outline><sx:sync version="1" id="QeqQ03W6Z06dQwdtQ44xDQ==" /></outline><sx:sync version="1" id="EvzfufVwSU2wwvNhsnoggw==" /></outline><outline text="Résultat"><outline text="modèle final de même taille (ou légèrement augmenté), mais optimisé pour une tâche."><sx:sync version="1" id="ZllB08ZBhkaEVRN8/czcog==" /></outline><sx:sync version="1" id="sk5wCt9Q7kmtQx7PoSzWdA==" /></outline><outline text="Cas d’usage"><outline text="Chatbots spécialisés,"><sx:sync version="1" id="R+SoZ1FfKk256Eko52EYdw==" /></outline><outline text="Domaines professionnels (médical, juridique…),"><sx:sync version="1" id="Wva/M4/bTE+Zn5QPfuNGEg==" /></outline><outline text="Adaptation de style ou ton."><sx:sync version="1" id="4xQXs/R9LEWJHU5D7wViWw==" /></outline><sx:sync version="1" id="yHYeAlaT3kyCLfvHxAjTTg==" /></outline><sx:sync version="1" id="JdFC4HRpc0O+gBYQK/YH2w==" /></outline><outline text="Distillation"><outline text="Définition"><outline text="transférer les connaissances d’un gros modèle vers un modèle plus petit."><sx:sync version="1" id="RCAYLgLU70CtFJgU6mDbmw==" /></outline><sx:sync version="1" id="nLRoyHlqxUKT3w4cJs3oDg==" /></outline><outline text="Objectif"><outline text="réduire la taille du modèle tout en gardant des performances correctes."><sx:sync version="1" id="lwm7BnMPdE+dh4ikbv/dCQ==" /></outline><sx:sync version="1" id="vdmmCuKypE2T/k6ZcrG/Lg==" /></outline><outline text="Méthode"><outline text="Le grand modèle (professeur) produit des réponses,"><sx:sync version="1" id="kONoa2FWx0uBDA5CLhp8Fw==" /></outline><outline text="Le petit modèle (élève) apprend à reproduire ces réponses."><sx:sync version="1" id="epFqOp1aCUOkNm4xXk3Myg==" /></outline><sx:sync version="1" id="QPOTPiY40USaDtDPBjQlIw==" /></outline><outline text="Résultat"><outline text="modèle plus léger, rapide, moins gourmand en ressources, avec légère baisse de performance."><sx:sync version="1" id="FSKn92i7dk2Ks0rcQuHjrg==" /></outline><sx:sync version="1" id="pYj5dqVjM06PmaUSF/9qXw==" /></outline><outline text="Cas d’usage"><outline text="Déploiement sur mobile ou serveurs limités,"><sx:sync version="1" id="hWKycxckokSK10r53qrbHA==" /></outline><outline text="Réduction des coûts d’inférence,"><sx:sync version="1" id="0Q8IZpFqokSkQ59KkSViMA==" /></outline><outline text="Utilisation en temps réel."><sx:sync version="1" id="jiiPjFEg2E+yzz+XxYPfJg==" /></outline><sx:sync version="1" id="GzeNa+yGgU6fvTtL+ZhuMw==" /></outline><sx:sync version="1" id="I1JottGFDUeboDN4EPQpIQ==" /></outline><outline text="Liens et différences"><outline text="Points communs"><outline text="Les deux sont des méthodes de post-entraînement,"><sx:sync version="1" id="L3MY1Y3Ma0SyYbDw0ig/5A==" /></outline><outline text="Elles adaptent un modèle déjà pré-entraîné."><sx:sync version="1" id="iaOUK5xWf068XRUQdOUihw==" /></outline><sx:sync version="1" id="c5g6OFiMKkaM5TpnbfKJmQ==" /></outline><outline text="Différences"><outline text="Fine-tuning"><outline text="spécialisation sans réduction de taille,"><sx:sync version="1" id="bUkZowYDb02OzSZyDvaEwA==" /></outline><sx:sync version="1" id="f1lzY1+EOk6MPhRXjJdnow==" /></outline><outline text="Distillation"><outline text="compression avec un modèle final plus petit."><sx:sync version="1" id="fOlACjCGMk6CwDtwHC7B5g==" /></outline><sx:sync version="1" id="iiCipNVhrUCelzPgq9GN3g==" /></outline><sx:sync version="1" id="SQ633gjbz0emC1LMW1uc9A==" /></outline><outline text="Complémentarité"><outline text="On peut fine-tuner un modèle puis distiller le résultat pour le rendre plus léger."><sx:sync version="1" id="SneyfipIyEiIpXKS+Qo6lA==" /></outline><sx:sync version="1" id="56+zCq6VhE2rvdUC33QGwA==" /></outline><sx:sync version="1" id="oK5njsJTJEGB0hPm06/ZWw==" /></outline><sx:sync version="1" id="DZ4u8f7Cm0Sykg85eRJLsg==" /></outline><outline text="Quand est ce que le RAG sera plus performant qu'un Finetuning ?"><outline text="1. Données fréquemment mises à jour"><outline text="- RAG permet d'accéder à des informations toujours à jour via une base documentaire."><sx:sync version="1" id="D4veISyhqUacvKY47GU9mA==" /></outline><outline text="- Fine-tuning fige les informations au moment de l'entraînement."><sx:sync version="1" id="efmcyzmG802wRI8Z530Z4w==" /></outline><sx:sync version="1" id="IhaFOU/YpUy+hTbiVrObig==" /></outline><outline text="2. Volume de données très important"><outline text="- RAG interroge directement une base externe sans devoir stocker tout en mémoire du modèle."><sx:sync version="1" id="txJ9nyYINUiRaE712Bi5lg==" /></outline><outline text="- Fine-tuning devient inefficace quand le dataset est trop volumineux."><sx:sync version="1" id="11/PMypDJECZquYp6HNq3w==" /></outline><sx:sync version="1" id="yZaIgMtZU0C16B+u0IajrA==" /></outline><outline text="3. Précision des faits et vérifiabilité"><outline text="- RAG peut citer les sources utilisées, très utile pour les domaines sensibles."><sx:sync version="1" id="hMsvdJzBE02N5vBQAshoUg==" /></outline><outline text="- Fine-tuning ne permet pas d'expliquer ou justifier ses réponses."><sx:sync version="1" id="sTiDAaxFh0yaFAjfxN8VGg==" /></outline><sx:sync version="1" id="EMSHaBbXM0iuUjWReoNYpg==" /></outline><outline text="4. Multiples domaines à couvrir"><outline text="- RAG fonctionne bien sur plusieurs sujets grâce à la recherche documentaire."><sx:sync version="1" id="rLEsjGgRjUKF+WGiTeP6Ng==" /></outline><outline text="- Fine-tuning reste souvent limité à un domaine spécifique."><sx:sync version="1" id="08v5Xo6Xwk2IqFZY7rdYzA==" /></outline><sx:sync version="1" id="k91FndsFX0uXEV+14HWzxg==" /></outline><outline text="5. Contraintes de ressources"><outline text="- RAG ne nécessite pas de réentraîner le modèle, seulement une base documentaire."><sx:sync version="1" id="4yJh2K5dGEy0N2BjrhiHyw==" /></outline><outline text="- Fine-tuning demande GPU, temps de calcul et gestion de l'entraînement."><sx:sync version="1" id="LVG9fMdEhkyn2Hym8qgqzw==" /></outline><sx:sync version="1" id="GHkmKmoCqUuap92Z+1vJew==" /></outline><sx:sync version="1" id="0quie+IsxEa+mFkFNAkgEg==" /></outline><outline text="LoRA : Low-Rank Adaptation"><outline text="3.1. Principe"><outline text="Fige les pondérations du modèle de base"><sx:sync version="1" id="jrk6vFpdUEuveX21k5/LMw==" /></outline><outline text="Ajoute matrices d'apprentissage bas-rang (LoRA) sur couches clés (attention)"><sx:sync version="1" id="jvIn5gS9Pkq66UUR6EwOhw==" /></outline><outline text="Analogie Lego : ajout de petites pièces sans reconstruire l'ensemble"><sx:sync version="1" id="2uEGvKBhmECFcEgWztMvbQ==" /></outline><sx:sync version="1" id="PmCdf9srkE2Ws65NmwH9UA==" /></outline><outline text="3.2. Avantages de LoRA"><outline text="Coût réduit : jusqu’à 98,4 % d’effort en moins"><sx:sync version="1" id="WiKwQSo2GUaU1dRmjlxBvA==" /></outline><outline text="Mémoire réduite : moins de RAM/GPU"><sx:sync version="1" id="VW/6PwxxdU6veggwj2iFmQ==" /></outline><outline text="Pas de surcharge de stockage : seul LoRA sauvegardé"><sx:sync version="1" id="HzDnqdzTRkC+x9s0GbTC9Q==" /></outline><outline text="Pas d’oubli catastrophique : base du modèle inchangée"><sx:sync version="1" id="nSdDITm8KEe7gkEXNa7Rnw==" /></outline><sx:sync version="1" id="gwhAuhFE2UKhGOAr2weLzw==" /></outline><outline text="3.3. Fusion des poids"><outline text="Poids finaux = W + BA"><sx:sync version="1" id="6ZOZdZIuN0ukjqoruKeoGQ==" /></outline><outline text="Possibilité de fusionner les poids LoRA avec le modèle principal"><sx:sync version="1" id="bbY0eT0Z8UO/QF22IykI4g==" /></outline><sx:sync version="1" id="gXUpxMa88UGKDCAuSuz2Yw==" /></outline><sx:sync version="1" id="D/ZgxmqnDEmNrsgXxbzSWQ==" /></outline><outline text="Applications typiques du LORA "><outline text="1. Spécialisation de grands modèles de langage (LLM)"><outline text="- Adapter GPT, Llama, Falcon sur des tâches précises sans gros budget."><sx:sync version="1" id="BgyiJCocu0O0vyv4bCqbFg==" /></outline><outline text="- Exemples : chatbot médical, assistant juridique, support client."><sx:sync version="1" id="FRQUXHHBz02pc7sEYjtRLw==" /></outline><sx:sync version="1" id="pjuYJGWeekK85VSEzFmSyQ==" /></outline><outline text="2. Personnalisation de style"><outline text="- Modifier le ton ou la manière d’écrire (formel, amical, humoristique)."><sx:sync version="1" id="EkSuBaMDWkaMotoaa712qA==" /></outline><outline text="- Adaptation rapide pour personnalisation individuelle."><sx:sync version="1" id="tfQTOzu4dE+k2sdsIGSELg==" /></outline><sx:sync version="1" id="Tq5kQHHKukGn+l33ulasaw==" /></outline><outline text="3. Fine-tuning rapide sur des jeux de données limités"><outline text="- Utilisation efficace pour domaines avec peu de données annotées."><sx:sync version="1" id="aZv4YWDc60CDf5f9ByabiA==" /></outline><sx:sync version="1" id="3BEpcyWJNUCy/BQYx/gajQ==" /></outline><outline text="4. Adaptation multi-langues"><outline text="- Ajouter une nouvelle langue ou adapter un modèle multilingue à un dialecte spécifique."><sx:sync version="1" id="7yY2hm7Xu06oz7Ys16faRw==" /></outline><sx:sync version="1" id="GaHr0853jUKmCqPiq6SXWg==" /></outline><outline text="5. Applications industrielles légères"><outline text="- Déployer des modèles customisés sur des serveurs avec ressources limitées (GPU moyen)."><sx:sync version="1" id="gpBXDUNcl0ae8vP8RDV5rA==" /></outline><sx:sync version="1" id="MKAAkLyViUWYUUW9ZYPt6A==" /></outline><outline text="6. Couplage avec quantization"><outline text="- Utilisé avec QLoRA pour combiner faible mémoire et personnalisation rapide."><sx:sync version="1" id="IJ1+weIXbke1aF3IZl1YpA==" /></outline><sx:sync version="1" id="WnfhD/L56E24UpGMInvP0w==" /></outline><outline text="7. Applications dans la vision par ordinateur"><outline text="- LoRA est aussi appliqué à des modèles de vision (ex : segmentation, classification rapide)."><sx:sync version="1" id="Fjk5fzwJsUCydReADTaFkA==" /></outline><sx:sync version="1" id="2I5hPdc+I021TdMLiOUVHw==" /></outline><outline text="8. Recherche rapide et prototypage"><outline text="- Permet des cycles courts de tests d’adaptation sans coûts lourds d'entraînement complet."><sx:sync version="1" id="1/l63VtmBEGsatkjmz1MHA==" /></outline><sx:sync version="1" id="LKnZGHaE50m0XKnDQ+N3nw==" /></outline><sx:sync version="1" id="BGumC3zLR02CrTq3WR/3Ug==" /></outline><outline text="Autres méthodes PEFT"><outline text="4.1. Couches d'adaptation"><outline text="Insère petites couches dans le modèle"><sx:sync version="1" id="TD45Bou5IEW/A7ZA5YBmVA==" /></outline><outline text="Consommation modérée, léger ralentissement"><sx:sync version="1" id="vAFb6qeBVUiLZ1puaIo4Tw==" /></outline><sx:sync version="1" id="cQ9UdRRhjEWj10/7xafEbg==" /></outline><outline text="4.2. Prompt Tuning"><outline text="Modifie seulement les entrées textuelles"><sx:sync version="1" id="3palRN5QVEutkBWfxCZWvg==" /></outline><outline text="Très peu de paramètres, pas de changement d'architecture"><sx:sync version="1" id="odOaX7d9KECbEUUkmB4UXQ==" /></outline><sx:sync version="1" id="9oGMVeuirUqhFRq1Zcx0lw==" /></outline><outline text="4.3. Prefix Tuning"><outline text="Ajoute vecteurs préfixes en entrée"><sx:sync version="1" id="qBApkBmmZkelsmO2iEdMfQ==" /></outline><outline text="Peu de mémoire, pas de ralentissement"><sx:sync version="1" id="cVK2fQPUl0mQwxE3CujXnw==" /></outline><sx:sync version="1" id="tWU6q2Qxb0uM4qNwLUwQWA==" /></outline><outline text="4.4. Comparatif simplifié"><outline text="Couches d'adaptation : rapide à implémenter, modéré"><sx:sync version="1" id="ViDE6XcQ/E+ozB2XtAJA2w==" /></outline><outline text="Prompt tuning : ultra léger, mais conception complexe"><sx:sync version="1" id="E/xck4QubUGuWcK1TfZaXA==" /></outline><outline text="Prefix tuning : intermédiaire entre prompt et LoRA"><sx:sync version="1" id="xygufNCTI0uWp62uLg6l2g==" /></outline><sx:sync version="1" id="wo+iNG5wrEiDRCf0Bo8ueg==" /></outline><sx:sync version="1" id="u7xAtS5tI0CK8/dH9YFzBQ==" /></outline><outline text="LoRA appliqué aux Transformateurs de Vision (ViT)"><outline text="6.1. Cas d'usage ViT"><outline text="Moins de calcul et stockage"><sx:sync version="1" id="k9I4AduboE61+U5elSEDSw==" /></outline><outline text="Adaptateurs interchangeables entre tâches"><sx:sync version="1" id="q5ZO9jEXQkymejt2ouJR6w==" /></outline><sx:sync version="1" id="DJKChbp740O5nCGOyCtqaw==" /></outline><outline text="6.2. Workflow LoRA ViT"><outline text="Installation : transformers, datasets, peft"><sx:sync version="1" id="o7v8NcSH2kKmsnpc0/ieHA==" /></outline><outline text="Prétraitement : Datasets (Food101, Cats vs Dogs), id2label"><sx:sync version="1" id="gLHmWu626Ea5kAtE7av4HA==" /></outline><outline text="Modèle : Vit-base pré-entraîné (ex : google/vit-base-patch16-224-in21k)"><sx:sync version="1" id="b/sYLH69TEeUFHEZ4F7xqQ==" /></outline><outline text="Configuration LoRA : r=16, alpha=16, query/value ciblés, dropout=0.1"><sx:sync version="1" id="bouzNeLhaE2iCb746lPZMg==" /></outline><outline text="Réduction paramètres : 85M → 600k (~0.7%)"><sx:sync version="1" id="jz6FaAOM5ECOFplF74nKbg==" /></outline><outline text="Entraînement via Trainer Hugging Face"><sx:sync version="1" id="DyHLpYZyrEal8c6aAYXBNg==" /></outline><outline text="Inférence : changement dynamique d’adaptateurs LoRA"><sx:sync version="1" id="lOcR92pg9UqHKe07ZgVAmg==" /></outline><sx:sync version="1" id="LHxVTMdc80+7fl8fZ8RqiQ==" /></outline><outline text="6.3. Résultats observés"><outline text="Food101 : précision 94,6%, modèle 2.7MB"><sx:sync version="1" id="ogmMJ8BBYkmU/foO7YcsMQ==" /></outline><outline text="Cats vs Dogs : précision 99,48%, modèle 2.4MB"><sx:sync version="1" id="0kgQbGgpu0+mxgRESzEp2Q==" /></outline><outline text="Modèles légers, adaptables, haute précision"><sx:sync version="1" id="ZdTEqxDAck2TFudCe8oEYw==" /></outline><sx:sync version="1" id="gFfbwbHnnEuphDuANCea/Q==" /></outline><sx:sync version="1" id="pQ0sIYgaQUmMDgm+uWnf5w==" /></outline><outline text="Considérations théoriques"><outline text="5.1. Efficacité vs Performance"><outline text="PEFT = moins de paramètres → possible perte légère performance"><sx:sync version="1" id="0mBZd0zoLU6KKf2P17gpHA==" /></outline><sx:sync version="1" id="Wa7goSR+Tk6WyA3/V6oziw==" /></outline><outline text="5.2. Sélection des couches"><outline text="Couches d’attention les plus efficaces"><sx:sync version="1" id="gTesHueh00WRUOQw9B5pqQ==" /></outline><outline text="Couches basses moins pertinentes pour tâches spécifiques"><sx:sync version="1" id="FwS1x9VcgkeMsj+oa6W22w==" /></outline><sx:sync version="1" id="Kolpr3o1D0OEuVFjb6JDjw==" /></outline><outline text="5.3. Oubli catastrophique"><outline text="LoRA atténue ce risque en figeant la majorité du modèle"><sx:sync version="1" id="oPtvUJNtM0aFJWl7dv+Gwg==" /></outline><sx:sync version="1" id="HoZszdaD8EKb84b7Ytn1xg==" /></outline><sx:sync version="1" id="7UcsSF0nskmG5JDtOILKvA==" /></outline><outline text="Pruning"><outline text="1. Définition"><outline text="- Technique qui consiste à supprimer des parties d’un modèle (poids, neurones, couches) jugées inutiles."><sx:sync version="1" id="7L+6JzWSqkWSTbPvar2SjQ==" /></outline><outline text="- Objectif : rendre le modèle plus léger sans trop dégrader les performances."><sx:sync version="1" id="byvzNrnSU0upoPvgZ9dhIQ==" /></outline><sx:sync version="1" id="jzYb6DSwYEqUkPU8dsPE5Q==" /></outline><outline text="2. Objectifs principaux"><outline text="- Réduire la taille mémoire."><sx:sync version="1" id="hIyMJbchs0SOvG8uNBc7uA==" /></outline><outline text="- Accélérer l’exécution (inférence plus rapide)."><sx:sync version="1" id="wOAN12TAG0K3tuFFYxN+GQ==" /></outline><outline text="- Faciliter le déploiement sur des machines limitées (mobile, edge)."><sx:sync version="1" id="5vS8O2BMTEGswzK7b3d9EQ==" /></outline><sx:sync version="1" id="vF1zxFme5EGJ17n1GQzXLg==" /></outline><outline text="3. Types de pruning"><outline text="- Pruning par poids : suppression des poids de très faible valeur."><sx:sync version="1" id="DYk9zslTKESm3LPPyBi/0w==" /></outline><outline text="- Pruning par neurones : suppression de neurones entiers dans les couches."><sx:sync version="1" id="opbopM11ckWtTGXl8DfOLg==" /></outline><outline text="- Pruning structurel : suppression de structures entières (ex : têtes d’attention)."><sx:sync version="1" id="otTYds0NJECbkE+m0RBVOQ==" /></outline><outline text="- Pruning dynamique : activation/suppression variable selon l’entrée ou l’inférence."><sx:sync version="1" id="ScV33n2ALEW4P3McI7ZBiA==" /></outline><sx:sync version="1" id="/MTNy6yXU02ZC0IMAsw/6w==" /></outline><outline text="4. Cas d’usage"><outline text="- Optimisation de modèles pour l’embarqué."><sx:sync version="1" id="eOlYBoL5zkGtxAy34mAT2A==" /></outline><outline text="- Réduction des coûts d’inférence serveur."><sx:sync version="1" id="7NBYomitsU6ejLxhUid6CQ==" /></outline><outline text="- Post-traitement après fine-tuning pour accélération supplémentaire."><sx:sync version="1" id="0dT1wR6xLEe4UDZ/tFXaFQ==" /></outline><sx:sync version="1" id="UtbtZ11Cu06nFRYVOOEo+w==" /></outline><outline text="5. Limites"><outline text="- Trop de pruning peut dégrader fortement la qualité des résultats."><sx:sync version="1" id="V5K5845dk0GMlGJCnzMSbQ==" /></outline><outline text="- Nécessite souvent un fine-tuning ou réentraînement après pruning pour récupérer de bonnes performances."><sx:sync version="1" id="wbFQl1BCG0qeCuKi6ASCyQ==" /></outline><sx:sync version="1" id="H7VcvSOOyU+N+74bgnUD9A==" /></outline><sx:sync version="1" id="Xg8OHt0zukWSx+nU2JNrcQ==" /></outline><outline text="Quantisation"><outline text="1. Définition"><outline text="- Technique qui consiste à **réduire la précision numérique des poids et des activations** d’un modèle (ex : passer de 32 bits à 8 bits ou 4 bits)."><sx:sync version="1" id="Ol27C3/7WU+B09g+EB3Xag==" /></outline><outline text="- Objectif : **réduire la taille du modèle** et **accélérer les calculs**."><sx:sync version="1" id="yyFG3RLx4k+2my8h/+eINg==" /></outline><sx:sync version="1" id="r1T75ji6PkWYFPNiZlUqFQ==" /></outline><outline text="2. Objectifs principaux"><outline text="- Diminuer la mémoire utilisée (taille des poids réduite)."><sx:sync version="1" id="sq6X5/0yqUK7Rp5xNeolXw==" /></outline><outline text="- Accélérer l’inférence (opérations plus rapides)."><sx:sync version="1" id="YRRZCM4qzki5bul85NL3EQ==" /></outline><outline text="- Faciliter l’exécution sur des matériels plus simples (CPU, petits GPU)."><sx:sync version="1" id="h7KGdr1ijEecrOLx1tIIrQ==" /></outline><sx:sync version="1" id="mla9gMxyF0W0FHhQpgBsug==" /></outline><outline text="3. Types de quantisation"><outline text="- Quantisation post-entrainement : après entraînement, on transforme les poids sans retraining."><sx:sync version="1" id="C8BL9Vo2rkejqpdusjZpVw==" /></outline><outline text="- Quantisation avec recalibrage : nécessite un petit jeu de données pour ajuster la quantisation."><sx:sync version="1" id="0vTgOvde1UGtFA/py2r10w==" /></outline><outline text="- Quantisation lors de l’entraînement (QAT) : intégrée pendant l’entraînement pour meilleure stabilité."><sx:sync version="1" id="DzT2a0f8cka+7iM2ZbfgDQ==" /></outline><outline text="- Quantisation binaire (rare) : poids réduits à seulement 1 bit (extrême)."><sx:sync version="1" id="TXIDvgV5KUyDSi0HAOV9ag==" /></outline><sx:sync version="1" id="5vVwjmLOP0uUAlxBK/1R1Q==" /></outline><outline text="4. Cas d’usage"><outline text="- Déploiement de modèles LLM (GPT, Llama…) en 8 bits, 4 bits ou moins."><sx:sync version="1" id="1Y8Bigfx+EqExinm0t/Hkw==" /></outline><outline text="- Réduction des coûts sur les serveurs et les équipements embarqués."><sx:sync version="1" id="48tCJ7xzOESjieULG7TECw==" /></outline><outline text="- Accélération des applications temps réel."><sx:sync version="1" id="uNYA8Uc1BU2D5ThfSh886g==" /></outline><sx:sync version="1" id="cqONu863akiMmY4/P4nPwg==" /></outline><outline text="5. Limites"><outline text="- Légère perte de précision, surtout en quantisation agressive."><sx:sync version="1" id="/Uq/o2YHuke8q6pVO61plQ==" /></outline><outline text="- Certaines architectures sont moins compatibles avec des quantisations extrêmes."><sx:sync version="1" id="Wx4qfZhxPUucYyFeRnh//w==" /></outline><outline text="- Nécessite des bibliothèques spécifiques (bitsandbytes, GGUF, GPTQ) pour une bonne efficacité."><sx:sync version="1" id="GRkMh8tPFE+in1ekMsqR/w==" /></outline><sx:sync version="1" id="8KwLLB1DEE+tgGjpMTNXWA==" /></outline><sx:sync version="1" id="v0W4PkG5qUqupoNPSMXDdg==" /></outline><outline text="Conclusion"><outline text="LoRA : alternative efficace au fine-tuning complet"><sx:sync version="1" id="zTkst70jE0meM2gvYnQTZQ==" /></outline><outline text="Gains : calcul, mémoire, stockage"><sx:sync version="1" id="tOZlZySld0CW/WPhGGdwrw==" /></outline><outline text="Préserve connaissances générales"><sx:sync version="1" id="xPpwMYJYJ0COOjH1ydb1Ww==" /></outline><outline text="Permet modèles spécialisés légers, adaptateurs interchangeables"><sx:sync version="1" id="sO3vi759HUaW/aTUfkhziw==" /></outline><outline text="Compatible LLM et ViT"><sx:sync version="1" id="O8MVVU8Y+0SmswJv+m8/8A==" /></outline><sx:sync version="1" id="qRoQGkP09k+W3FvTdeVadg==" /></outline></body></opml>
