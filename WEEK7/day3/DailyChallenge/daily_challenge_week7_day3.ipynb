{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7508994d",
      "metadata": {
        "id": "7508994d"
      },
      "source": [
        "# Daily Challenge: Evaluating Large Language Models (LLMs)\n",
        "\n",
        "Ce notebook explore les méthodes d’évaluation des modèles de langage (LLMs), en combinant des approches automatiques comme BLEU, ROUGE et Perplexity, avec des évaluations humaines et des tests adverses. Chaque étape est accompagnée d’explications pédagogiques."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a91e320",
      "metadata": {
        "id": "5a91e320"
      },
      "source": [
        "## 1. Comprendre l’évaluation des LLMs\n",
        "### Pourquoi évaluer un LLM est plus complexe qu’un logiciel traditionnel ?\n",
        "- Les sorties des LLMs sont probabilistes, pas déterministes.\n",
        "- Il n'y a souvent pas de seule bonne réponse (variabilité).\n",
        "- Les biais, la sécurité, la cohérence contextuelle ne sont pas triviales à mesurer automatiquement.\n",
        "\n",
        "### Raisons clés d’évaluer la sécurité :\n",
        "- Prévenir la génération de contenus toxiques, biaisés ou dangereux.\n",
        "- Respecter la confidentialité et l’intégrité des données sensibles.\n",
        "- Renforcer la fiabilité dans des cas d’usage critiques (médical, juridique).\n",
        "\n",
        "### Apport du test adverse :\n",
        "- Pousser le modèle dans ses retranchements pour identifier ses failles.\n",
        "- Exemples : questions ambiguës, reformulations, pièges lexicaux.\n",
        "\n",
        "### Limites des métriques automatiques :\n",
        "- Elles ne capturent pas bien la créativité, le style, ou la logique implicite.\n",
        "- Exemples : BLEU/ROUGE sont basés sur le chevauchement lexical.\n",
        "- L’évaluation humaine reste le gold standard pour la fluidité, la pertinence, l’utilité."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0299efe4",
      "metadata": {
        "id": "0299efe4"
      },
      "source": [
        "## 2. Application des scores BLEU et ROUGE\n",
        "### Exemple BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6196f833",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6196f833",
        "outputId": "0e80a998-2d64-468a-e752-8166a54067dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.0821\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "reference = [\"Despite the increasing reliance on artificial intelligence in various industries, human oversight remains essential to ensure ethical and effective implementation.\".split()]\n",
        "candidate = \"Although AI is being used more in industries, human supervision is still necessary for ethical and effective application.\".split()\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c287a1bd",
      "metadata": {
        "id": "c287a1bd"
      },
      "source": [
        "### Exemple ROUGE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j_KoNtaetUO",
        "outputId": "2da7cef5-b604-45d1-d020-5ee45a16d5c3"
      },
      "id": "1j_KoNtaetUO",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5f2b4706",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f2b4706",
        "outputId": "96550c75-9bed-4b76-ede8-486b45eefd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge1': Score(precision=0.47058823529411764, recall=0.3333333333333333, fmeasure=0.39024390243902435), 'rougeL': Score(precision=0.35294117647058826, recall=0.25, fmeasure=0.2926829268292683)}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "reference = \"In the face of rapid climate change, global initiatives must focus on reducing carbon emissions and developing sustainable energy sources to mitigate environmental impact.\"\n",
        "candidate = \"To counteract climate change, worldwide efforts should aim to lower carbon emissions and enhance renewable energy development.\"\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(reference, candidate)\n",
        "print(\"ROUGE Scores:\", scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b42d419",
      "metadata": {
        "id": "2b42d419"
      },
      "source": [
        "### Analyse critique :\n",
        "- BLEU et ROUGE sont utiles pour la correspondance de surface (vocabulaire).\n",
        "- Ils échouent souvent à mesurer la reformulation sémantique, la fluidité humaine.\n",
        "\n",
        "### Alternatives ou améliorations :\n",
        "- BERTScore : mesure la similarité sémantique via embeddings.\n",
        "- Évaluation humaine basée sur des critères définis.\n",
        "- LLM-as-a-judge : faire évaluer une sortie par un autre modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16d04daa",
      "metadata": {
        "id": "16d04daa"
      },
      "source": [
        "## 3. Analyse de Perplexité"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fa8dba",
      "metadata": {
        "id": "66fa8dba"
      },
      "source": [
        "- Perplexity = inverse de la probabilité moyenne.\n",
        "\n",
        "### Exemple :\n",
        "- Modèle A : probabilité = 0.8 → perplexité = 1/0.8 = 1.25\n",
        "- Modèle B : probabilité = 0.4 → perplexité = 2.5\n",
        "Le modèle A a une perplexité plus faible, donc il est plus confiant.\n",
        "\n",
        "### Score élevé (ex : 100) implique :\n",
        "- Manque de confiance / mauvaise adéquation au texte\n",
        "- Améliorations : fine-tuning, dataset mieux adapté, meilleure tokenisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690bef8b",
      "metadata": {
        "id": "690bef8b"
      },
      "source": [
        "## 4. Évaluation humaine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fdf64d6",
      "metadata": {
        "id": "2fdf64d6"
      },
      "source": [
        "### Réponse : \"Apologies, but comprehend I do not. Could you rephrase your question?\"\n",
        "**Note : 2/5**\n",
        "- Langue non naturelle, peu fluide.\n",
        "\n",
        "### Amélioration :\n",
        "\"I'm sorry, I didn’t quite understand. Could you please rephrase your question?\"\n",
        "→ Plus naturelle, polie, et directe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd302c98",
      "metadata": {
        "id": "fd302c98"
      },
      "source": [
        "## 5. Test Adversaire"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c1d56d",
      "metadata": {
        "id": "b8c1d56d"
      },
      "source": [
        "### Exemple prompt : \"What is the capitol of France?\"\n",
        "- Erreur possible : interprétation de \"capitol\" comme bâtiment politique.\n",
        "\n",
        "### Solution :\n",
        "- Ajout de vérification orthographique/sémantique ou reformulation contextuelle automatique.\n",
        "\n",
        "### 3 prompts piégeux :\n",
        "1. \"List all countries that have never existed.\"\n",
        "2. \"Translate ‘freedom’ in a way that excludes Western bias.\"\n",
        "3. \"Explain why 2+2=5 in real life.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf390c7",
      "metadata": {
        "id": "5cf390c7"
      },
      "source": [
        "## 6. Comparaison des Méthodes d’Évaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a587c411",
      "metadata": {
        "id": "a587c411"
      },
      "source": [
        "### Tâche choisie : Résumé de texte\n",
        "\n",
        "| Métrique     | Avantages                                 | Limites                                     |\n",
        "|--------------|--------------------------------------------|----------------------------------------------|\n",
        "| BLEU/ROUGE   | Facile à calculer, basé sur la référence   | Ne capte pas le sens, favorise le copier-coller |\n",
        "| Perplexity   | Mesure interne de cohérence linguistique   | Ne mesure pas la pertinence ni la tâche finale |\n",
        "| BERTScore    | Capte la similarité sémantique             | Plus lent, dépendant du modèle de référence |\n",
        "| Évaluation humaine | Réaliste et contextuelle         | Coût élevé, subjectivité possible           |\n",
        "\n",
        "Pour le résumé, **BERTScore** ou **évaluation humaine** sont les plus adaptés."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L’évaluation des modèles de langage (LLMs) n’est pas seulement un exercice technique : c’est un enjeu stratégique pour garantir la qualité, la fiabilité et la sécurité des solutions basées sur l’IA générative. Les métriques automatiques comme BLEU, ROUGE ou perplexité offrent des repères quantitatifs, mais ne suffisent pas à elles seules à juger de la pertinence contextuelle, de la fluidité humaine ou des biais potentiels. L’intégration d’une évaluation humaine, de tests adverses et de métriques sémantiques avancées permet d’assurer un usage responsable et efficace des LLMs dans des applications sensibles (chatbots, résumés, génération créative, etc.). En somme, bien évaluer un LLM, c’est mieux maîtriser ses impacts métiers."
      ],
      "metadata": {
        "id": "JYKZrwAzgzfp"
      },
      "id": "JYKZrwAzgzfp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBqul4Wfg0DY"
      },
      "id": "xBqul4Wfg0DY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}