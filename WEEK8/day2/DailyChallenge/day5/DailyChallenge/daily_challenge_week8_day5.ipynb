{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c19b53d",
   "metadata": {},
   "source": [
    "# Projet : BaristaBot — Assistant de Commande de Café avec LangGraph + Gemini API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c2347",
   "metadata": {},
   "source": [
    "\n",
    "Ce projet a pour but de créer un agent conversationnel capable de :\n",
    "- Prendre des commandes de boissons (café/thé) en langage naturel\n",
    "- Gérer dynamiquement un menu avec un outil\n",
    "- Confirmer ou modifier les commandes\n",
    "- Utiliser une structure d'état persistante avec LangGraph\n",
    "- Intégrer l'API Gemini via LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langgraph==0.2.45 langchain-google-genai==2.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2555cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class OrderState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    order: list[str]\n",
    "    finished: bool\n",
    "\n",
    "BARISTABOT_SYSINT = (\n",
    "    \"system\",\n",
    "    \"Tu es BaristaBot, un assistant de commande pour un café. Tu guides le client dans sa commande \"\n",
    "    \"à partir d’un menu. Tu ne parles que des produits du menu, pas de sujets hors sujet. \"\n",
    "    \"Tu dois vérifier les articles, utiliser les fonctions disponibles (add_to_order, confirm_order, place_order, etc.), \"\n",
    "    \"et confirmer la commande avant de la soumettre.\"\n",
    ")\n",
    "\n",
    "WELCOME_MSG = \"Bienvenue chez BaristaBot ! Tapez `q` pour quitter. Que puis-je vous servir aujourd’hui ?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "def chatbot(state: OrderState) -> OrderState:\n",
    "    messages = [BARISTABOT_SYSINT] + state[\"messages\"]\n",
    "    return {\"messages\": [llm.invoke(messages)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "user_msg = (\"user\", \"Je voudrais un cappuccino s’il vous plaît.\")\n",
    "state = {\"messages\": [user_msg], \"order\": [], \"finished\": False}\n",
    "state = chatbot(state)\n",
    "\n",
    "for msg in state[\"messages\"]:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "def human_node(state: OrderState) -> OrderState:\n",
    "    print(\"Bot:\", state[\"messages\"][-1].content)\n",
    "    user_input = input(\"Vous : \")\n",
    "\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        state[\"finished\"] = True\n",
    "\n",
    "    return state | {\"messages\": [(\"user\", user_input)]}\n",
    "\n",
    "def chatbot_with_welcome_msg(state: OrderState) -> OrderState:\n",
    "    if state[\"messages\"]:\n",
    "        output = llm.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
    "    else:\n",
    "        output = AIMessage(content=WELCOME_MSG)\n",
    "    return state | {\"messages\": [output]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal\n",
    "\n",
    "def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
    "    return END if state.get(\"finished\") else \"chatbot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_menu() -> str:\n",
    "    return '''\n",
    "    MENU:\n",
    "    - Espresso, Americano, Cold Brew\n",
    "    - Latte, Cappuccino, Cortado, Mocha, Flat White\n",
    "    - Chai Latte, Matcha Latte, Earl Grey, London Fog\n",
    "    - Modificateurs : lait (entier, avoine, amande), chaud/froid, décaféiné, etc.\n",
    "    - Soy milk est en rupture de stock.\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [get_menu]\n",
    "tool_node = ToolNode(tools)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def maybe_route_to_tools(state: OrderState) -> str:\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"human\"\n",
    "\n",
    "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
    "    if state[\"messages\"]:\n",
    "        output = llm_with_tools.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
    "    else:\n",
    "        output = AIMessage(content=WELCOME_MSG)\n",
    "    return state | {\"messages\": [output]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce860aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections.abc import Iterable\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from random import randint\n",
    "\n",
    "@tool\n",
    "def add_to_order(drink: str, modifiers: Iterable[str]) -> str: pass\n",
    "\n",
    "@tool\n",
    "def confirm_order() -> str: pass\n",
    "\n",
    "@tool\n",
    "def get_order() -> str: pass\n",
    "\n",
    "@tool\n",
    "def clear_order(): pass\n",
    "\n",
    "@tool\n",
    "def place_order() -> int: pass\n",
    "\n",
    "def order_node(state: OrderState) -> OrderState:\n",
    "    tool_msg = state[\"messages\"][-1]\n",
    "    order = state.get(\"order\", [])\n",
    "    outbound_msgs = []\n",
    "    order_placed = False\n",
    "\n",
    "    for call in tool_msg.tool_calls:\n",
    "        name, args = call[\"name\"], call[\"args\"]\n",
    "        if name == \"add_to_order\":\n",
    "            drink = args[\"drink\"]\n",
    "            mods = \", \".join(args[\"modifiers\"]) or \"sans modificateur\"\n",
    "            order.append(f\"{drink} ({mods})\")\n",
    "            response = \"\n",
    "\".join(order)\n",
    "        elif name == \"confirm_order\":\n",
    "            print(\"Commande :\")\n",
    "            for item in order:\n",
    "                print(\" -\", item)\n",
    "            response = input(\"Est-ce correct ? \")\n",
    "        elif name == \"get_order\":\n",
    "            response = \"\n",
    "\".join(order) or \"(aucune commande)\"\n",
    "        elif name == \"clear_order\":\n",
    "            order.clear()\n",
    "            response = \"Commande vidée\"\n",
    "        elif name == \"place_order\":\n",
    "            print(\"Commande envoyée à la cuisine !\")\n",
    "            order_placed = True\n",
    "            response = f\"Temps estimé : {randint(1, 5)} minutes\"\n",
    "        else:\n",
    "            raise NotImplementedError(name)\n",
    "\n",
    "        outbound_msgs.append(ToolMessage(content=response, name=name, tool_call_id=call[\"id\"]))\n",
    "\n",
    "    return {\"messages\": outbound_msgs, \"order\": order, \"finished\": order_placed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_builder = StateGraph(OrderState)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"ordering\", order_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
    "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"ordering\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph_with_order_tools = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"recursion_limit\": 100}\n",
    "state = graph_with_order_tools.invoke({\"messages\": [], \"order\": [], \"finished\": False}, config)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
