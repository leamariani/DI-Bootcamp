{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a283509f",
   "metadata": {},
   "source": [
    "‚úÖ 1Ô∏è‚É£ Comprendre le probl√®me\n",
    "üëâ Expliquer l‚Äôobjectif : par exemple pr√©dire si une tumeur est b√©nigne ou maligne.\n",
    "üëâ Identifier la variable √† pr√©dire (diagnosis), et le contexte m√©tier (cancer du sein, diagnostic m√©dical).\n",
    "\n",
    "‚úÖ 2Ô∏è‚É£ Collecte des donn√©es\n",
    "üëâ O√π trouver les donn√©es‚ÄØ? Ici c‚Äôest un CSV d√©j√† pr√™t, donc pas de collecte suppl√©mentaire.\n",
    "üëâ V√©rifier la source (donn√©es fiables‚ÄØ?).\n",
    "\n",
    "‚úÖ 3Ô∏è‚É£ Nettoyage des donn√©es\n",
    "üëâ V√©rifier les valeurs manquantes\n",
    "üëâ Corriger ou supprimer les valeurs incoh√©rentes\n",
    "üëâ Supprimer les colonnes inutiles (id)\n",
    "üëâ Transformer les colonnes cat√©gorielles (par ex. diagnosis ‚Üí 0/1)\n",
    "\n",
    "‚úÖ 4Ô∏è‚É£ S√©lection des fonctionnalit√©s (feature selection)\n",
    "üëâ Se demander‚ÄØ: toutes les colonnes sont-elles utiles‚ÄØ?\n",
    "üëâ Parfois on peut en retirer pour simplifier le mod√®le (par ex. corr√©lations tr√®s fortes entre colonnes, redondances)\n",
    "\n",
    "‚úÖ 5Ô∏è‚É£ Choix du mod√®le\n",
    "üëâ Ici‚ÄØ: r√©gression logistique, car on a 2 classes\n",
    "üëâ on pourrait aussi essayer SVM, arbre de d√©cision, etc.\n",
    "\n",
    "‚úÖ 6Ô∏è‚É£ Entra√Ænement\n",
    "üëâ D√©couper en train/test\n",
    "üëâ Appliquer .fit() sur le jeu d‚Äôentra√Ænement\n",
    "\n",
    "‚úÖ 7Ô∏è‚É£ √âvaluation\n",
    "üëâ Mesurer accuracy, confusion matrix, pr√©cision, rappel\n",
    "üëâ Regarder s‚Äôil y a des biais, ou si une classe est mal pr√©dite\n",
    "\n",
    "‚úÖ 8Ô∏è‚É£ Optimisation\n",
    "üëâ Ajuster les hyperparam√®tres\n",
    "üëâ Essayer d‚Äôautres mod√®les\n",
    "üëâ Faire du feature engineering (nouvelles variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4f6be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e7838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Nombre de lignes:569,Nombre de colonnes:33\n",
      "id                           int64\n",
      "diagnosis                   object\n",
      "radius_mean                float64\n",
      "texture_mean               float64\n",
      "perimeter_mean             float64\n",
      "area_mean                  float64\n",
      "smoothness_mean            float64\n",
      "compactness_mean           float64\n",
      "concavity_mean             float64\n",
      "concave points_mean        float64\n",
      "symmetry_mean              float64\n",
      "fractal_dimension_mean     float64\n",
      "radius_se                  float64\n",
      "texture_se                 float64\n",
      "perimeter_se               float64\n",
      "area_se                    float64\n",
      "smoothness_se              float64\n",
      "compactness_se             float64\n",
      "concavity_se               float64\n",
      "concave points_se          float64\n",
      "symmetry_se                float64\n",
      "fractal_dimension_se       float64\n",
      "radius_worst               float64\n",
      "texture_worst              float64\n",
      "perimeter_worst            float64\n",
      "area_worst                 float64\n",
      "smoothness_worst           float64\n",
      "compactness_worst          float64\n",
      "concavity_worst            float64\n",
      "concave points_worst       float64\n",
      "symmetry_worst             float64\n",
      "fractal_dimension_worst    float64\n",
      "Unnamed: 32                float64\n",
      "dtype: object\n",
      "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
      "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
      "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
      "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
      "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
      "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
      "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
      "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
      "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
      "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
      "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
      "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
      "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
      "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
      "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
      "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
      "\n",
      "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count        569.000000         569.000000       569.000000   \n",
      "mean           0.132369           0.254265         0.272188   \n",
      "std            0.022832           0.157336         0.208624   \n",
      "min            0.071170           0.027290         0.000000   \n",
      "25%            0.116600           0.147200         0.114500   \n",
      "50%            0.131300           0.211900         0.226700   \n",
      "75%            0.146000           0.339100         0.382900   \n",
      "max            0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
      "count            569.000000      569.000000               569.000000   \n",
      "mean               0.114606        0.290076                 0.083946   \n",
      "std                0.065732        0.061867                 0.018061   \n",
      "min                0.000000        0.156500                 0.055040   \n",
      "25%                0.064930        0.250400                 0.071460   \n",
      "50%                0.099930        0.282200                 0.080040   \n",
      "75%                0.161400        0.317900                 0.092080   \n",
      "max                0.291000        0.663800                 0.207500   \n",
      "\n",
      "       Unnamed: 32  \n",
      "count          0.0  \n",
      "mean           NaN  \n",
      "std            NaN  \n",
      "min            NaN  \n",
      "25%            NaN  \n",
      "50%            NaN  \n",
      "75%            NaN  \n",
      "max            NaN  \n",
      "\n",
      "[8 rows x 32 columns]\n",
      "Nombre de valeur nulle:\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"breastCancerPredictionData.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(f\"Nombre de lignes:{df.shape[0]},Nombre de colonnes:{df.shape[1]}\")\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"Nombre de valeur nulle:\\n{df.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1c68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage des donnees\n",
    "#On remarque que les donnees sont bien nettoye pas de valeurs manquantes\n",
    "# mais il faut convertir la colonne diagnosis en nombre\n",
    "\"\"\"\n",
    "convertis la colonne diagnosis de lettres ('M' ou 'B') en nombres (1 ou 0). Cela fonctionne parfaitement.\n",
    "\n",
    "si relance exactement le m√™me code une deuxi√®me fois, la colonne diagnosis contient d√©j√† \n",
    "des nombres (1 ou 0). Donc la fonction .map({'M':1,'B':0}) ne trouve plus les cl√©s 'M' ou 'B', \n",
    "et renvoie NaN (c‚Äôest-√†-dire des valeurs manquantes) pour toutes les valeurs, car 1 et 0 n‚Äôexistent \n",
    "pas comme cl√©s dans le dictionnaire.\n",
    "\"\"\"\n",
    "if df['diagnosis'].dtype == 'object':\n",
    "    df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n",
    "else:\n",
    "    print(\"diagnosis est d√©j√† num√©rique, pas de conversion n√©cessaire.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74d43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeur double:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#verifier les doublons\n",
    "print(f\"Nombre de valeur double:\\n{df.duplicated().sum()}\")\n",
    "#y a pas de doublons donc on passe\n",
    "\n",
    "# supprimer la colonne id si pr√©sente\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "# supprimer colonne parasite si pr√©sente\n",
    "if 'Unnamed: 32' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 32'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387603b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs nulles apr√®s nettoyage :\n",
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: v√©rification encore une fois\n",
    "print(\"Valeurs nulles apr√®s nettoyage :\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df.to_csv(\"breastCancerPredictionData_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "#C'est une fonction qui va renforcer l'affichage plt.show() dans pycharm\n",
    "plt.switch_backend('TkAgg')\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(corr_matrix,cmap='coolwarm')\n",
    "plt.title(\"Matrice de correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc36af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'apres le graph .On commence large pour ne rien rater, et plus tard on pourra all√©ger le mod√®le si besoin.\n",
    "\n",
    "#Phase:Choix du mod√®le et entra√Ænement\n",
    "# (On pr√©pare les donn√©es, on apprend au mod√®le, puis on le teste pour voir s‚Äôil devine bien.)\n",
    "\n",
    "X = df.drop(columns=['diagnosis'])  # X = tout ce qui d√©crit la tumeur (taille, forme, etc.)\n",
    "y = df['diagnosis']                 # y = la r√©ponse (b√©nin ou malin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On met tout sur la m√™me √©chelle. Comme √ßa, aucune colonne n‚Äô√©crase les autres.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On partage les donn√©es\n",
    "#80% ‚Üí pour apprendre ,20% ‚Üí pour tester\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b96ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cr√©e notre mod√®le,c‚Äôest la ‚Äúmachine‚Äù qui va deviner b√©nin/malin\n",
    "logreg = LogisticRegression(max_iter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6773f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On apprend au mod√®le √† faire la diff√©rence entre b√©nin et malin\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On demande au mod√®le de faire des pr√©dictions sur les cas qu‚Äôil n‚Äôa jamais vus (les 20% test)\n",
    "y_pred = logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On regarde combien de bonnes r√©ponses il a faites.\n",
    "#accuracy = pourcentage de r√©ussite\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy de la r√©gression logistique : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase: √âvaluation approfondie\n",
    "\"\"\"\n",
    "confusion_matrix ‚Üí un tableau qui montre combien de b√©nins et de malins le mod√®le a bien class√©s ou rat√©s\n",
    "\n",
    "classification_report ‚Üí pr√©cision, rappel, F1-score\n",
    "pr√©cision = parmi ceux que le mod√®le dit ‚Äúmalin‚Äù, combien sont vraiment malins\n",
    "rappel = parmi les vrais malins, combien ont √©t√© d√©tect√©s\n",
    "F1-score = moyenne √©quilibr√©e entre pr√©cision et rappel\n",
    "\"\"\"\n",
    "# matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nRapport d√©taill√© :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"B√©nin\",\"Malin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e056f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le resultat\n",
    "\"\"\"\n",
    "Le mod√®le marche tr√®s bien, surtout pour dire qu‚Äôune tumeur est b√©nigne.\n",
    "Il est aussi tr√®s bon pour d√©tecter les malins, mais il en rate encore 5% ‚Äî\n",
    "donc on pourrait encore l‚Äôam√©liorer pour √©viter de manquer ces cas graves.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7147bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase: Optimisation\n",
    "\"\"\"\n",
    "L‚Äôoptimisation, c‚Äôest comme r√©gler la sensibilit√© d‚Äôun d√©tecteur.\n",
    "La validation crois√©e v√©rifie qu‚Äôil n‚Äôest pas tromp√© par un √©chantillon chanceux,\n",
    "et la recherche d‚Äôhyperparam√®tres lui donne le meilleur r√©glage\n",
    "\"\"\"\n",
    "# validation crois√©e sur 5 morceaux\n",
    "scores = cross_val_score(logreg, X_scaled, y, cv=5)\n",
    "\n",
    "print(f\"Scores validation crois√©e : {scores}\")\n",
    "print(f\"Score moyen : {scores.mean():.2f}\")\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=10000),\n",
    "    param_grid,\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "print(f\"Meilleur C : {grid.best_params_}\")\n",
    "print(f\"Meilleur score : {grid.best_score_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultat\n",
    "\"\"\"\n",
    "La validation crois√©e confirme que notre mod√®le est robuste,\n",
    "et la recherche d‚Äôhyperparam√®tres montre que la configuration de base √©tait d√©j√† bonne.\n",
    "Avec 98% de score moyen, c‚Äôest un excellent r√©sultat.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
