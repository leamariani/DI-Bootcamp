{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a934958",
   "metadata": {},
   "source": [
    "# Phase 1 : Exploration et Visualisation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Paramètres d'affichage\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv('ex2data1.csv', header=None)\n",
    "df = df[0].str.split(\",\", expand=True)\n",
    "df.columns = [\"Exam1\", \"Exam2\", \"Admitted\"]\n",
    "df = df.astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions et structure des données\n",
    "print(\"Dimensions :\", df.shape)\n",
    "print(\"Colonnes :\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types de données et valeurs manquantes\n",
    "print(df.info())\n",
    "print(\"\\nValeurs manquantes :\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43af6eb",
   "metadata": {},
   "source": [
    "## Visualisation des Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7132fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuage de points : scores des examens vs admission\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x='Exam1', y='Exam2', hue='Admitted', palette='Set1')\n",
    "plt.title('Scores aux Examens et Admission')\n",
    "plt.xlabel('Note à l\\'examen 1')\n",
    "plt.ylabel('Note à l\\'examen 2')\n",
    "plt.legend(title='Admis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1097cd",
   "metadata": {},
   "source": [
    "# Phase 2 : Régression Logistique avec scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c07de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des variables explicatives et de la cible\n",
    "X = df[['Exam1', 'Exam2']]\n",
    "y = df['Admitted']\n",
    "\n",
    "# Création et entraînement du modèle\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad35097",
   "metadata": {},
   "source": [
    "# Phase 3 : Prédictions et Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde64745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur l'ensemble du jeu de données\n",
    "y_pred = model.predict(X)\n",
    "print(\"Valeurs réelles :\", y.values[:10])\n",
    "print(\"Valeurs prédites :\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846123c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'accuracy\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy du modèle : {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eeace0",
   "metadata": {},
   "source": [
    "# Phase 4 : Interprétation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5babdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients appris\n",
    "coeffs = model.coef_[0]\n",
    "print(f\"Coefficient pour Exam1 : {coeffs[0]:.4f}\")\n",
    "print(f\"Coefficient pour Exam2 : {coeffs[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d94f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la frontière de décision\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x='Exam1', y='Exam2', hue='Admitted', palette='Set1')\n",
    "\n",
    "# Calcul de la frontière\n",
    "x_values = np.linspace(df['Exam1'].min(), df['Exam1'].max(), 100)\n",
    "y_values = -(model.intercept_[0] + model.coef_[0][0]*x_values) / model.coef_[0][1]\n",
    "plt.plot(x_values, y_values, label='Frontière de décision')\n",
    "\n",
    "plt.xlabel('Exam1')\n",
    "plt.ylabel('Exam2')\n",
    "plt.title('Frontière de décision du modèle')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc568b3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Le modèle semble globalement fiable, mais peut échouer sur des cas limites.\n",
    "Pour une meilleure performance, on pourrait ajouter d'autres variables explicatives (temps de préparation, motivation, etc.)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
